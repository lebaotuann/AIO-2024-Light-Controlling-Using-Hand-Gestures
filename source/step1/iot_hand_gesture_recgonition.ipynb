{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Tạo folder data để các bạn upload file 3 file data được tạo ra ở step 0 vào folder data\n",
        "# Các bạn upload file hand_gesture.yaml ngoài folder data\n",
        "!mkdir data/"
      ],
      "metadata": {
        "id": "JZJH1v68YX4M"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhc2257_m3K",
        "outputId": "af076823-b907-4a6a-a125-8db17de08b2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.18\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.18)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQmMu4bKVnkG",
        "outputId": "01cee000-0ba9-452f-917a-e2c5e2a9eb60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from  torch import nn\n",
        "import mediapipe as mp\n",
        "from torch import optim\n",
        "from datetime import datetime\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "xZPTB4Gm_8KF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(63, 128), # input layer\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 128), # second layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 128), # third layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 128), # fourth layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(128, len(list_label))  # Output layer\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x\n",
        "\n",
        "    def predict(self,x,threshold=0.8):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        chosen_ind = torch.argmax(softmax_prob,dim=1)\n",
        "        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n",
        "\n",
        "    def predict_with_known_class(self,x):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        return torch.argmax(softmax_prob,dim=1)\n",
        "\n",
        "    def score(self,logits):\n",
        "        return -torch.amax(logits,dim=1)"
      ],
      "metadata": {
        "id": "qdI0AaZt_38Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_dict_from_config_file(relative_path):\n",
        "    with open(relative_path,\"r\") as f:\n",
        "       label_tag = yaml.full_load(f)[\"gestures\"]\n",
        "    return label_tag"
      ],
      "metadata": {
        "id": "lJUGNVftADWJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandLandmarksDetector():\n",
        "    def __init__(self) -> None:\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
        "\n",
        "    def detectHand(self,frame):\n",
        "        hands = []\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        annotated_image = frame.copy()\n",
        "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_hand_landmarks is not None:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                hand = []\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    hand_landmarks,\n",
        "                    self.mp_hands.HAND_CONNECTIONS,\n",
        "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
        "                for landmark in hand_landmarks.landmark:\n",
        "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
        "                    hand.extend([x,y,z])\n",
        "            hands.append(hand)\n",
        "        return hands,annotated_image"
      ],
      "metadata": {
        "id": "3yzD6r0wTR0v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = pd.read_csv(data_file)\n",
        "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        one_hot_label = self.labels[idx]\n",
        "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
        "        return torch_data, one_hot_label"
      ],
      "metadata": {
        "id": "DQH1LReLB03s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.watched_metrics = np.inf\n",
        "\n",
        "    def early_stop(self, current_value):\n",
        "        if current_value < self.watched_metrics:\n",
        "            self.watched_metrics = current_value\n",
        "            self.counter = 0\n",
        "        elif current_value > (self.watched_metrics + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "h9prQCqNTXPS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
        "    # add auroc score\n",
        "    best_vloss = 1_000_000\n",
        "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
        "    for epoch in range(300):\n",
        "        #training step\n",
        "        model.train(True)\n",
        "        running_loss = 0.0\n",
        "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for batch_number,data in enumerate(trainloader):\n",
        "            inputs,labels = data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(inputs)\n",
        "\n",
        "            loss = loss_function(preds,labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        # validating step\n",
        "        model.train(False)\n",
        "        running_vloss = 0.0\n",
        "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for i, vdata in enumerate(val_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            preds = model(vinputs)\n",
        "            vloss = loss_function(preds, vlabels)\n",
        "            running_vloss += vloss.item()\n",
        "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
        "\n",
        "        # Log the running loss averaged per batch\n",
        "        # for both training and validation\n",
        "        print(f\"Epoch {epoch}: \")\n",
        "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
        "        avg_vloss = running_vloss / len(val_loader)\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "        print('Training vs. Validation Loss',\n",
        "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                        epoch + 1)\n",
        "        print('Training vs. Validation accuracy',\n",
        "                        { 'Training' : acc_train.compute().item()\n",
        "                        , 'Validation' : acc_val.compute().item() },\n",
        "                        epoch + 1)\n",
        "\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        if early_stopper.early_stop(avg_vloss):\n",
        "            print(f\"stopping at epoch {epoch}, minimum: {early_stopper.watched_metrics}\")\n",
        "            break\n",
        "\n",
        "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(acc_val.compute())\n",
        "    return model, best_model_path"
      ],
      "metadata": {
        "id": "fPBj338O_tcY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER_PATH=\"./data/\"\n",
        "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
        "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
        "save_path = './models'\n",
        "os.makedirs(save_path,exist_ok=True)\n",
        "\n",
        "trainset = CustomImageDataset(train_path)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=40, shuffle=True)\n",
        "\n",
        "valset = CustomImageDataset(os.path.join(val_path))\n",
        "val_loader = torch.utils.data.DataLoader(valset,batch_size=50, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
      ],
      "metadata": {
        "id": "MhE1acacBG8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3c198b-3608-4ed1-c76f-0f1a9659c3fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \n",
            "Accuracy train:0.2957770824432373, val:0.41106557846069336\n",
            "LOSS train 1.5567206629391375 valid 1.4633536192835594\n",
            "Training vs. Validation Loss {'Training': 1.5567206629391375, 'Validation': 1.4633536192835594} 1\n",
            "Training vs. Validation accuracy {'Training': 0.2957770824432373, 'Validation': 0.41106557846069336} 1\n",
            "Epoch 1: \n",
            "Accuracy train:0.503807544708252, val:0.7762295007705688\n",
            "LOSS train 1.2164522117581862 valid 0.9160429257519391\n",
            "Training vs. Validation Loss {'Training': 1.2164522117581862, 'Validation': 0.9160429257519391} 2\n",
            "Training vs. Validation accuracy {'Training': 0.503807544708252, 'Validation': 0.7762295007705688} 2\n",
            "Epoch 2: \n",
            "Accuracy train:0.8276219964027405, val:0.8827868700027466\n",
            "LOSS train 0.630570151888091 valid 0.4931184158717491\n",
            "Training vs. Validation Loss {'Training': 0.630570151888091, 'Validation': 0.4931184158717491} 3\n",
            "Training vs. Validation accuracy {'Training': 0.8276219964027405, 'Validation': 0.8827868700027466} 3\n",
            "Epoch 3: \n",
            "Accuracy train:0.9380408525466919, val:0.8598360419273376\n",
            "LOSS train 0.2906293555066503 valid 0.4534283241931805\n",
            "Training vs. Validation Loss {'Training': 0.2906293555066503, 'Validation': 0.4534283241931805} 4\n",
            "Training vs. Validation accuracy {'Training': 0.9380408525466919, 'Validation': 0.8598360419273376} 4\n",
            "Epoch 4: \n",
            "Accuracy train:0.9664243459701538, val:0.8733606338500977\n",
            "LOSS train 0.16509821736093225 valid 0.46713481272561286\n",
            "Training vs. Validation Loss {'Training': 0.16509821736093225, 'Validation': 0.46713481272561286} 5\n",
            "Training vs. Validation accuracy {'Training': 0.9664243459701538, 'Validation': 0.8733606338500977} 5\n",
            "Epoch 5: \n",
            "Accuracy train:0.9710972905158997, val:0.8758196830749512\n",
            "LOSS train 0.12366984651006502 valid 0.5108665536111459\n",
            "Training vs. Validation Loss {'Training': 0.12366984651006502, 'Validation': 0.5108665536111459} 6\n",
            "Training vs. Validation accuracy {'Training': 0.9710972905158997, 'Validation': 0.8758196830749512} 6\n",
            "Epoch 6: \n",
            "Accuracy train:0.9759432077407837, val:0.8725410103797913\n",
            "LOSS train 0.09152254215602217 valid 0.5605964029186443\n",
            "Training vs. Validation Loss {'Training': 0.09152254215602217, 'Validation': 0.5605964029186443} 7\n",
            "Training vs. Validation accuracy {'Training': 0.9759432077407837, 'Validation': 0.8725410103797913} 7\n",
            "Epoch 7: \n",
            "Accuracy train:0.981135368347168, val:0.8766393661499023\n",
            "LOSS train 0.08474874965332706 valid 0.5526313675309582\n",
            "Training vs. Validation Loss {'Training': 0.08474874965332706, 'Validation': 0.5526313675309582} 8\n",
            "Training vs. Validation accuracy {'Training': 0.981135368347168, 'Validation': 0.8766393661499023} 8\n",
            "Epoch 8: \n",
            "Accuracy train:0.9806161522865295, val:0.8704918026924133\n",
            "LOSS train 0.07198444899043133 valid 0.6003027583081311\n",
            "Training vs. Validation Loss {'Training': 0.07198444899043133, 'Validation': 0.6003027583081311} 9\n",
            "Training vs. Validation accuracy {'Training': 0.9806161522865295, 'Validation': 0.8704918026924133} 9\n",
            "Epoch 9: \n",
            "Accuracy train:0.985981285572052, val:0.8770492076873779\n",
            "LOSS train 0.059283543496938616 valid 0.6064530186774892\n",
            "Training vs. Validation Loss {'Training': 0.059283543496938616, 'Validation': 0.6064530186774892} 10\n",
            "Training vs. Validation accuracy {'Training': 0.985981285572052, 'Validation': 0.8770492076873779} 10\n",
            "Epoch 10: \n",
            "Accuracy train:0.987712025642395, val:0.8729507923126221\n",
            "LOSS train 0.051284171721159386 valid 0.642237497796505\n",
            "Training vs. Validation Loss {'Training': 0.051284171721159386, 'Validation': 0.642237497796505} 11\n",
            "Training vs. Validation accuracy {'Training': 0.987712025642395, 'Validation': 0.8729507923126221} 11\n",
            "Epoch 11: \n",
            "Accuracy train:0.9849429130554199, val:0.8758196830749512\n",
            "LOSS train 0.045723457062809635 valid 0.67710920362051\n",
            "Training vs. Validation Loss {'Training': 0.045723457062809635, 'Validation': 0.67710920362051} 12\n",
            "Training vs. Validation accuracy {'Training': 0.9849429130554199, 'Validation': 0.8758196830749512} 12\n",
            "Epoch 12: \n",
            "Accuracy train:0.9882312417030334, val:0.8713114857673645\n",
            "LOSS train 0.04241434359312828 valid 0.702069038080504\n",
            "Training vs. Validation Loss {'Training': 0.04241434359312828, 'Validation': 0.702069038080504} 13\n",
            "Training vs. Validation accuracy {'Training': 0.9882312417030334, 'Validation': 0.8713114857673645} 13\n",
            "Epoch 13: \n",
            "Accuracy train:0.9884042739868164, val:0.8651639223098755\n",
            "LOSS train 0.04406486690879382 valid 0.6700718763730488\n",
            "Training vs. Validation Loss {'Training': 0.04406486690879382, 'Validation': 0.6700718763730488} 14\n",
            "Training vs. Validation accuracy {'Training': 0.9884042739868164, 'Validation': 0.8651639223098755} 14\n",
            "Epoch 14: \n",
            "Accuracy train:0.9894427061080933, val:0.8729507923126221\n",
            "LOSS train 0.04206763773289477 valid 0.7104670232911118\n",
            "Training vs. Validation Loss {'Training': 0.04206763773289477, 'Validation': 0.7104670232911118} 15\n",
            "Training vs. Validation accuracy {'Training': 0.9894427061080933, 'Validation': 0.8729507923126221} 15\n",
            "Epoch 15: \n",
            "Accuracy train:0.9918656945228577, val:0.8549180030822754\n",
            "LOSS train 0.04050252883582665 valid 0.7901392066376186\n",
            "Training vs. Validation Loss {'Training': 0.04050252883582665, 'Validation': 0.7901392066376186} 16\n",
            "Training vs. Validation accuracy {'Training': 0.9918656945228577, 'Validation': 0.8549180030822754} 16\n",
            "Epoch 16: \n",
            "Accuracy train:0.9922118186950684, val:0.875\n",
            "LOSS train 0.03739870897020567 valid 0.7050626033109582\n",
            "Training vs. Validation Loss {'Training': 0.03739870897020567, 'Validation': 0.7050626033109582} 17\n",
            "Training vs. Validation accuracy {'Training': 0.9922118186950684, 'Validation': 0.875} 17\n",
            "Epoch 17: \n",
            "Accuracy train:0.9918656945228577, val:0.8655737638473511\n",
            "LOSS train 0.033032320781032846 valid 0.748229111903565\n",
            "Training vs. Validation Loss {'Training': 0.033032320781032846, 'Validation': 0.748229111903565} 18\n",
            "Training vs. Validation accuracy {'Training': 0.9918656945228577, 'Validation': 0.8655737638473511} 18\n",
            "Epoch 18: \n",
            "Accuracy train:0.9918656945228577, val:0.875\n",
            "LOSS train 0.03411460232856715 valid 0.7403396431542398\n",
            "Training vs. Validation Loss {'Training': 0.03411460232856715, 'Validation': 0.7403396431542398} 19\n",
            "Training vs. Validation accuracy {'Training': 0.9918656945228577, 'Validation': 0.875} 19\n",
            "Epoch 19: \n",
            "Accuracy train:0.9922118186950684, val:0.8606557250022888\n",
            "LOSS train 0.03284719262577208 valid 0.778874546391268\n",
            "Training vs. Validation Loss {'Training': 0.03284719262577208, 'Validation': 0.778874546391268} 20\n",
            "Training vs. Validation accuracy {'Training': 0.9922118186950684, 'Validation': 0.8606557250022888} 20\n",
            "Epoch 20: \n",
            "Accuracy train:0.9942886829376221, val:0.8741803169250488\n",
            "LOSS train 0.027684862447645644 valid 0.7768645785469502\n",
            "Training vs. Validation Loss {'Training': 0.027684862447645644, 'Validation': 0.7768645785469502} 21\n",
            "Training vs. Validation accuracy {'Training': 0.9942886829376221, 'Validation': 0.8741803169250488} 21\n",
            "Epoch 21: \n",
            "Accuracy train:0.9923849105834961, val:0.86147540807724\n",
            "LOSS train 0.030074825903786153 valid 0.8911655117168423\n",
            "Training vs. Validation Loss {'Training': 0.030074825903786153, 'Validation': 0.8911655117168423} 22\n",
            "Training vs. Validation accuracy {'Training': 0.9923849105834961, 'Validation': 0.86147540807724} 22\n",
            "Epoch 22: \n",
            "Accuracy train:0.9927310347557068, val:0.8463114500045776\n",
            "LOSS train 0.030833121532863328 valid 0.9363302807346509\n",
            "Training vs. Validation Loss {'Training': 0.030833121532863328, 'Validation': 0.9363302807346509} 23\n",
            "Training vs. Validation accuracy {'Training': 0.9927310347557068, 'Validation': 0.8463114500045776} 23\n",
            "Epoch 23: \n",
            "Accuracy train:0.9922118186950684, val:0.8577868938446045\n",
            "LOSS train 0.03233537301581738 valid 0.8608937101815761\n",
            "Training vs. Validation Loss {'Training': 0.03233537301581738, 'Validation': 0.8608937101815761} 24\n",
            "Training vs. Validation accuracy {'Training': 0.9922118186950684, 'Validation': 0.8577868938446045} 24\n",
            "Epoch 24: \n",
            "Accuracy train:0.9944617748260498, val:0.8508196473121643\n",
            "LOSS train 0.02122993460165915 valid 0.901041904749537\n",
            "Training vs. Validation Loss {'Training': 0.02122993460165915, 'Validation': 0.901041904749537} 25\n",
            "Training vs. Validation accuracy {'Training': 0.9944617748260498, 'Validation': 0.8508196473121643} 25\n",
            "Epoch 25: \n",
            "Accuracy train:0.9941155910491943, val:0.875\n",
            "LOSS train 0.028372356762049782 valid 0.7683713850861125\n",
            "Training vs. Validation Loss {'Training': 0.028372356762049782, 'Validation': 0.7683713850861125} 26\n",
            "Training vs. Validation accuracy {'Training': 0.9941155910491943, 'Validation': 0.875} 26\n",
            "Epoch 26: \n",
            "Accuracy train:0.9960193634033203, val:0.8672131299972534\n",
            "LOSS train 0.021015658500154726 valid 0.8727220667879141\n",
            "Training vs. Validation Loss {'Training': 0.021015658500154726, 'Validation': 0.8727220667879141} 27\n",
            "Training vs. Validation accuracy {'Training': 0.9960193634033203, 'Validation': 0.8672131299972534} 27\n",
            "Epoch 27: \n",
            "Accuracy train:0.9916926026344299, val:0.8680328130722046\n",
            "LOSS train 0.03074062274576261 valid 0.7739707211811444\n",
            "Training vs. Validation Loss {'Training': 0.03074062274576261, 'Validation': 0.7739707211811444} 28\n",
            "Training vs. Validation accuracy {'Training': 0.9916926026344299, 'Validation': 0.8680328130722046} 28\n",
            "Epoch 28: \n",
            "Accuracy train:0.9942886829376221, val:0.8586065769195557\n",
            "LOSS train 0.01979060911228238 valid 0.8713550492130729\n",
            "Training vs. Validation Loss {'Training': 0.01979060911228238, 'Validation': 0.8713550492130729} 29\n",
            "Training vs. Validation accuracy {'Training': 0.9942886829376221, 'Validation': 0.8586065769195557} 29\n",
            "Epoch 29: \n",
            "Accuracy train:0.9948078989982605, val:0.8471311330795288\n",
            "LOSS train 0.016987285940257574 valid 0.9639830631951147\n",
            "Training vs. Validation Loss {'Training': 0.016987285940257574, 'Validation': 0.9639830631951147} 30\n",
            "Training vs. Validation accuracy {'Training': 0.9948078989982605, 'Validation': 0.8471311330795288} 30\n",
            "Epoch 30: \n",
            "Accuracy train:0.9953271150588989, val:0.8586065769195557\n",
            "LOSS train 0.019599377652349207 valid 0.9787146044764782\n",
            "Training vs. Validation Loss {'Training': 0.019599377652349207, 'Validation': 0.9787146044764782} 31\n",
            "Training vs. Validation accuracy {'Training': 0.9953271150588989, 'Validation': 0.8586065769195557} 31\n",
            "Epoch 31: \n",
            "Accuracy train:0.9946348071098328, val:0.86147540807724\n",
            "LOSS train 0.021339311901929562 valid 0.8101383726359107\n",
            "Training vs. Validation Loss {'Training': 0.021339311901929562, 'Validation': 0.8101383726359107} 32\n",
            "Training vs. Validation accuracy {'Training': 0.9946348071098328, 'Validation': 0.86147540807724} 32\n",
            "Epoch 32: \n",
            "Accuracy train:0.993423342704773, val:0.8663934469223022\n",
            "LOSS train 0.02185084997527783 valid 0.9777825882855739\n",
            "Training vs. Validation Loss {'Training': 0.02185084997527783, 'Validation': 0.9777825882855739} 33\n",
            "Training vs. Validation accuracy {'Training': 0.993423342704773, 'Validation': 0.8663934469223022} 33\n",
            "Epoch 33: \n",
            "Accuracy train:0.9941155910491943, val:0.8758196830749512\n",
            "LOSS train 0.026870411589886223 valid 0.8555152983914733\n",
            "Training vs. Validation Loss {'Training': 0.026870411589886223, 'Validation': 0.8555152983914733} 34\n",
            "Training vs. Validation accuracy {'Training': 0.9941155910491943, 'Validation': 0.8758196830749512} 34\n",
            "stopping at epoch 33, minimum: 0.4534283241931805\n",
            "tensor(0.8758)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "DATA_FOLDER_PATH=\"./data/\"\n",
        "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
        "\n",
        "# Test DataLoader instantiation\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=20, shuffle=False)\n",
        "\n",
        "network = NeuralNetwork()\n",
        "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
        "\n",
        "network.eval()\n",
        "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
        "for i, test_data in enumerate(test_loader):\n",
        "    test_input, test_label = test_data\n",
        "\n",
        "    preds = network(test_input)\n",
        "    acc_test.update(preds, test_label)\n",
        "\n",
        "print(network.__class__.__name__)\n",
        "print(f\"Accuracy of model:{acc_test.compute().item()}\")\n",
        "print(\"========================================================================\")"
      ],
      "metadata": {
        "id": "WuKEiiC_BWDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59687d6-a839-4f70-c07c-7d62c1b5b5ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork\n",
            "Accuracy of model:0.7481171488761902\n",
            "========================================================================\n"
          ]
        }
      ]
    }
  ]
}